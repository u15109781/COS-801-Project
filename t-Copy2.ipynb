{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2999ec9a",
   "metadata": {},
   "source": [
    "DATA IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2d2230",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b63b39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b972d8a9",
   "metadata": {},
   "source": [
    "PARAGRAPH SPLITTING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9d734c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feebf5f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850b2408",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efb3d946",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from pandas import json_normalize\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "\n",
    "import os\n",
    "#sys.path.append(os.path.abspath(\"pan-code/clef22/style-change-detection/evaluator\"))\n",
    "#!pip install evaluator\n",
    "#from evaluator import *\n",
    "from sentence_transformers import SentenceTransformer, InputExample, util, losses\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from typing import List\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1538a044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Post Number                                JSON Data  Authors  \\\n",
      "0            1        {'authors': 2, 'changes': [1, 0]}        2   \n",
      "1            2  {'authors': 3, 'changes': [1, 1, 0, 1]}        3   \n",
      "2            3     {'authors': 3, 'changes': [1, 1, 1]}        3   \n",
      "3            4           {'authors': 2, 'changes': [1]}        2   \n",
      "4            5     {'authors': 4, 'changes': [1, 1, 1]}        4   \n",
      "\n",
      "        Changes                                          Text Data  \\\n",
      "0        [1, 0]  I'm not arguing with you here, I'm simply tryi...   \n",
      "1  [1, 1, 0, 1]  Biden has the power to write an executive orde...   \n",
      "2     [1, 1, 1]  In general, be courteous to others. Debate/dis...   \n",
      "3           [1]  Second, until late in the 20th century, the Ot...   \n",
      "4     [1, 1, 1]  Arming and supplying a generation of hostile y...   \n",
      "\n",
      "                                       splitted_text  \n",
      "0  [I'm not arguing with you here, I'm simply try...  \n",
      "1  [Biden has the power to write an executive ord...  \n",
      "2  [In general, be courteous to others. Debate/di...  \n",
      "3  [Second, until late in the 20th century, the O...  \n",
      "4  [Arming and supplying a generation of hostile ...  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the folder containing the JSON and text files\n",
    "folder_path = r\"C:\\Users\\EBRAHIMR2\\Downloads\\Data Science Masters\\Modules\\COS 801\\pan23-multi-author-analysis-dataset1\\pan23-multi-author-analysis-dataset1-train\"\n",
    "\n",
    "# Lists to store data\n",
    "json_data_list = []\n",
    "text_data_list = []\n",
    "authors_list = []\n",
    "changes_list = []\n",
    "\n",
    "# Loop through files in the folder\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.startswith(\"truth-problem-\") and file_name.endswith(\".json\"):\n",
    "        json_file_path = os.path.join(folder_path, file_name)\n",
    "        \n",
    "        # Extract the post number from the JSON file name\n",
    "        post_number = int(file_name.split(\"-\")[-1].split(\".\")[0])\n",
    "        \n",
    "        # Construct the corresponding text file name\n",
    "        text_file_name = f\"problem-{post_number}.txt\"\n",
    "        text_file_path = os.path.join(folder_path, text_file_name)\n",
    "        \n",
    "        if os.path.exists(json_file_path) and os.path.exists(text_file_path):\n",
    "\n",
    "            # Read JSON data\n",
    "            with open(json_file_path, \"r\", encoding=\"utf-8\") as json_file:\n",
    "                json_data = json.load(json_file)\n",
    "                json_data_list.append(json_data)\n",
    "                \n",
    "                # Extract authors and changes from JSON\n",
    "                authors_list.append(json_data['authors'])\n",
    "                changes_list.append(json_data['changes'])\n",
    "            \n",
    "            # Read text file\n",
    "            with open(text_file_path, \"r\", encoding=\"utf-8\") as text_file:\n",
    "                text_data = text_file.read()\n",
    "                text_data_list.append(text_data)\n",
    "\n",
    "# Create a DataFrame\n",
    "data = pd.DataFrame({'Post Number': range(1, len(json_data_list) + 1),\n",
    "                     'JSON Data': json_data_list,\n",
    "                     'Authors': authors_list,\n",
    "                     'Changes': changes_list,\n",
    "                     'Text Data': text_data_list})\n",
    "\n",
    "# Function to split text into paragraphs\n",
    "def split_into_paragraphs(text):\n",
    "    return text.splitlines()\n",
    "\n",
    "# Apply the function to split text into paragraphs and add as a new column\n",
    "data['splitted_text'] = data['Text Data'].apply(split_into_paragraphs)\n",
    "\n",
    "# Print the first few rows of the DataFrame\n",
    "print(data.head())\n",
    "\n",
    "# Export the DataFrame to an Excel file\n",
    "data.to_excel(\"output_data1.xlsx\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acc66c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c5473be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_reproducibility(seed):\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  \n",
    "  # Pytorch\n",
    "  torch.use_deterministic_algorithms(True)\n",
    "  torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a90a796",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from transformers import AutoTokenizer\n",
    "from sentence_transformers import InputExample\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def create_contrastive_examples(df: pd.DataFrame, tokenizer: AutoTokenizer, max_length: int, max_samples: int):\n",
    "    rows = []\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        # Assuming 'splitted_text' is the column containing your text data\n",
    "        document = df['splitted_text'].iloc[i]\n",
    "        \n",
    "        # Assuming 'Authors' is the column containing author information\n",
    "        authors = df['Authors'].iloc[i]\n",
    "\n",
    "        if len(authors) != len(document):\n",
    "            continue\n",
    "\n",
    "        for i in range(len(document)):\n",
    "            for j in range(len(document)):\n",
    "                if i != j:\n",
    "                    new_row = {}\n",
    "\n",
    "                    text1 = document[i][:sum([len(t) + 1 for t in tokenizer.tokenize(document[i])[:max_length]])]\n",
    "                    text2 = document[j][:sum([len(t) + 1 for t in tokenizer.tokenize(document[j])[:max_length]])]\n",
    "\n",
    "                    new_row[\"text1\"] = text1\n",
    "                    new_row[\"text2\"] = text2\n",
    "\n",
    "                    if authors[i] != authors[j]:\n",
    "                        new_row[\"label\"] = 0  # 0 if different\n",
    "                    else:\n",
    "                        new_row[\"label\"] = 1  # 1 if same\n",
    "\n",
    "                    rows.append(new_row)\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=['text1', 'text2', 'label'])\n",
    "\n",
    "    # Sample the required positive and negative samples\n",
    "    pos_samples = df[df[\"label\"] == 1]\n",
    "    neg_samples = df[df[\"label\"] == 0]\n",
    "    \n",
    "    if len(pos_samples) > max_samples // 2:\n",
    "        pos_samples = pos_samples.sample(max_samples // 2)\n",
    "    if len(neg_samples) > max_samples // 2:\n",
    "        neg_samples = neg_samples.sample(max_samples // 2)    \n",
    "\n",
    "    df = pd.concat([pos_samples, neg_samples], axis=0, ignore_index=True).sample(frac=1)\n",
    "\n",
    "    # From this create a dataset which can be handled by sentence-transformers\n",
    "    train_examples = []\n",
    "    for i, row in df.iterrows():\n",
    "        train_examples.append(InputExample(texts=[row[\"text1\"], row[\"text2\"]], label=row[\"label\"]))\n",
    "\n",
    "    return np.array(train_examples)\n",
    "\n",
    "# Example usage:\n",
    "# train_examples = create_contrastive_examples(your_dataframe, your_tokenizer, your_max_length, your_max_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe6df9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from sentence_transformers import InputExample\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def create_triplet_examples(df, tokenizer, max_length, n_per_document, max_samples, model, margin, mine_all=True, mine_hard=False, mine_semihard=False, is_task1=False):\n",
    "    rows = []\n",
    "    rows_hard = []\n",
    "    rows_shard = []\n",
    "    \n",
    "    # Assuming 'splitted_text' is the column containing your text data\n",
    "    documents = df['splitted_text']\n",
    "    \n",
    "    # Assuming 'Authors' is the column containing author information\n",
    "    authors = df['Authors']\n",
    "    \n",
    "    # Your dataset structure might differ, adjust accordingly\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        used_idxs = []\n",
    "        n_remaining = n_per_document\n",
    "\n",
    "        # Get the indexes of each author\n",
    "        author_idxs = {}\n",
    "        for index, value in enumerate(authors[i]):\n",
    "            if value not in author_idxs:\n",
    "                author_idxs[value] = []\n",
    "            author_idxs[value].append(index)\n",
    "\n",
    "        if is_task1:\n",
    "            # Take the hard example (the change one)\n",
    "            changes = [int(authors[i][j] == authors[i][j+1]) for j in range(len(authors[i])-1)]\n",
    "            change_idx = changes.index(0)\n",
    "\n",
    "            try:\n",
    "                a_idx = random.choice([x for x in author_idxs[authors[i][change_idx]] if x != change_idx])\n",
    "            except IndexError:\n",
    "                continue\n",
    "            pos_idx = change_idx\n",
    "            neg_idx = change_idx + 1\n",
    "\n",
    "            new_row = {}\n",
    "\n",
    "            new_row[\"anchor\"] = documents[i][a_idx][:sum([len(t) + 1 for t in tokenizer.tokenize(documents[i][a_idx])[:max_length]])]\n",
    "            new_row[\"pos\"] = documents[i][pos_idx][:sum([len(t) + 1 for t in tokenizer.tokenize(documents[i][pos_idx])[:max_length]])]\n",
    "            new_row[\"neg\"] = documents[i][neg_idx][:sum([len(t) + 1 for t in tokenizer.tokenize(documents[i][neg_idx])[:max_length]])]\n",
    "\n",
    "            rows_shard.append(new_row)\n",
    "            used_idxs.append((a_idx, pos_idx, neg_idx))\n",
    "\n",
    "            n_remaining -= 1\n",
    "        else:\n",
    "            if all([len(author_idxs[k]) == 1 for k in author_idxs]):\n",
    "                continue\n",
    "\n",
    "        # I could compute how many combinations are possible but it's too hard\n",
    "        idx_errors = 0\n",
    "        while n_remaining > 0:\n",
    "            if idx_errors > 5:\n",
    "                break\n",
    "            try:\n",
    "                # Sample a random author\n",
    "                anchor_author = random.choice(list(author_idxs.keys()))\n",
    "\n",
    "                # Get a paragraph from that author (anchor)\n",
    "                a_idx = random.choice(author_idxs[anchor_author])\n",
    "\n",
    "                # Get another paragraph from the same author\n",
    "                pos_idx = random.choice([x for x in author_idxs[anchor_author] if x != a_idx])\n",
    "\n",
    "                # Sample another author\n",
    "                neg_author = random.choice([x for x in list(author_idxs.keys()) if x != anchor_author])\n",
    "\n",
    "                # Get a paragraph from that author\n",
    "                neg_idx = random.choice(author_idxs[neg_author])\n",
    "            except IndexError:\n",
    "                idx_errors += 1\n",
    "                continue\n",
    "\n",
    "            if (a_idx, pos_idx, neg_idx) in used_idxs:\n",
    "                idx_errors += 1\n",
    "                continue\n",
    "            else:\n",
    "                used_idxs.append((a_idx, pos_idx, neg_idx))\n",
    "                new_row = {}\n",
    "\n",
    "                new_row[\"anchor\"] = documents[i][a_idx][:sum([len(t) + 1 for t in tokenizer.tokenize(documents[i][a_idx])[:max_length]])]\n",
    "                new_row[\"pos\"] = documents[i][pos_idx][:sum([len(t) + 1 for t in tokenizer.tokenize(documents[i][pos_idx])[:max_length]])]\n",
    "                new_row[\"neg\"] = documents[i][neg_idx][:sum([len(t) + 1 for t in tokenizer.tokenize(documents[i][neg_idx])[:max_length]])]\n",
    "\n",
    "                if mine_hard or mine_semihard:\n",
    "                    # Compute embeddings\n",
    "                    a_embedding = model.encode([new_row[\"anchor\"]], convert_to_tensor=True)\n",
    "                    p_embedding = model.encode([new_row[\"pos\"]], convert_to_tensor=True)\n",
    "                    n_embedding = model.encode([new_row[\"neg\"]], convert_to_tensor=True)\n",
    "\n",
    "                    # Compute distance between anchor and positive\n",
    "                    a_p_dist = 1 - util.cos_sim(a_embedding, p_embedding).cpu().item()\n",
    "                    # Compute distance between anchor and negative\n",
    "                    a_n_dist = 1 - util.cos_sim(a_embedding, n_embedding).cpu().item()\n",
    "\n",
    "                    if a_n_dist < a_p_dist:\n",
    "                        # Hard example\n",
    "                        if mine_hard:\n",
    "                            rows_hard.append(new_row)\n",
    "                    elif a_n_dist < a_p_dist + margin and a_n_dist > a_p_dist:\n",
    "                        # Semi hard example\n",
    "                        if mine_semihard:\n",
    "                            rows_shard.append(new_row)\n",
    "                    else:\n",
    "                        if mine_all:\n",
    "                            rows.append(new_row)\n",
    "                    n_remaining -= 1\n",
    "                else:\n",
    "                    rows.append(new_row)\n",
    "                    n_remaining -= 1\n",
    "\n",
    "    print(f\"N easy:{len(rows)}, N hard: {len(rows_hard)}, N semihard:{len(rows_shard)}\")\n",
    "    random.shuffle(rows_shard)\n",
    "    random.shuffle(rows_hard)\n",
    "    random.shuffle(rows)\n",
    "\n",
    "    all_rows = [*rows_shard, *rows_hard, *rows]\n",
    "    if len(all_rows) < max_samples:\n",
    "        all_rows = all_rows[:max_samples]\n",
    "    print(len(all_rows))\n",
    "\n",
    "    df = pd.DataFrame(all_rows, columns=['anchor', 'pos', 'neg'])\n",
    "\n",
    "    # From this create a dataset which can be handled by sentence-transformers\n",
    "# From this create a dataset which can be handled by sentence-transformers\n",
    "# From this create a dataset which can be handled by sentence-transformers\n",
    "    train_examples = []\n",
    "    for i, row in df.iterrows():\n",
    "        train_examples.append(InputExample(texts=[row[\"anchor\"], row[\"pos\"], row[\"neg\"]]))\n",
    "\n",
    "    return np.array(train_examples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "219f923d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_same_diff_contrastive(model, dataloader):\n",
    "    model.eval()\n",
    "    same_sims = []\n",
    "    diff_sims = []\n",
    "\n",
    "    for idx, batch in enumerate(dataloader):\n",
    "        with torch.no_grad():\n",
    "            text1 = {k: batch[0][0][k].to(device) for k in batch[0][0]}\n",
    "            embeddings1 = model(text1)[\"sentence_embedding\"]\n",
    "\n",
    "            text2 = {k: batch[0][1][k].to(device) for k in batch[0][1]}\n",
    "            embeddings2 = model(text2)[\"sentence_embedding\"]\n",
    "\n",
    "            author_info = batch[1]\n",
    "\n",
    "            for i in range(len(author_info)):\n",
    "                same = author_info[i]\n",
    "                sim = util.cos_sim(embeddings1[i], embeddings2[i]).cpu().item()\n",
    "                if same == 1:\n",
    "                    same_sims.append(sim)\n",
    "                else:\n",
    "                    diff_sims.append(sim)\n",
    "    return same_sims, diff_sims\n",
    "\n",
    "def compute_same_diff_triplet(model, dataloader):\n",
    "    model.eval()\n",
    "    same_sims = []\n",
    "    diff_sims = []\n",
    "\n",
    "    for idx, batch in enumerate(dataloader):\n",
    "        with torch.no_dataloader():\n",
    "            anchor = {k: batch[0][0][k].to(device) for k in batch[0][0]}\n",
    "            embeddings_a = model(anchor)[\"sentence_embedding\"]\n",
    "\n",
    "            pos = {k: batch[0][1][k].to(device) for k in batch[0][1]}\n",
    "            embeddings_p = model(pos)[\"sentence_embedding\"]\n",
    "\n",
    "            neg = {k: batch[0][2][k].to(device) for k in batch[0][2]}\n",
    "            embeddings_n = model(neg)[\"sentence_embedding\"]\n",
    "\n",
    "            for i in range(anchor[\"input_ids\"].shape[0]):\n",
    "                sim_pos = util.cos_sim(embeddings_a[i], embeddings_p[i]).cpu().item()\n",
    "                sim_neg = util.cos_sim(embeddings_a[i], embeddings_n[i]).cpu().item()\n",
    "\n",
    "                same_sims.append(sim_pos)\n",
    "                diff_sims.append(sim_neg)\n",
    "\n",
    "    return same_sims, diff_sims\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b268ab1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "172306f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author change detected: False\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "def predict_author_change(model, paragraphs):\n",
    "    # Ensure your model is in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Initialize a list to store the similarity scores\n",
    "    similarity_scores = []\n",
    "\n",
    "    # Loop through successive pairs of passages\n",
    "    for i in range(1, len(paragraphs)):\n",
    "        # Encode the passages using the model\n",
    "        passage1_embedding = model.encode(paragraphs[i - 1], convert_to_tensor=True)\n",
    "        passage2_embedding = model.encode(paragraphs[i], convert_to_tensor=True)\n",
    "\n",
    "        # Compute the cosine similarity between the embeddings\n",
    "        similarity = util.pytorch_cos_sim(passage1_embedding, passage2_embedding)\n",
    "        \n",
    "        # Append the similarity score to the list\n",
    "        similarity_scores.append(similarity.item())\n",
    "\n",
    "    # Define a threshold for change detection\n",
    "    threshold = 0.5  # You can adjust this threshold as needed\n",
    "\n",
    "    # Check if any of the similarity scores indicate a change of author\n",
    "    author_change = any(score < threshold for score in similarity_scores)\n",
    "\n",
    "    return author_change\n",
    "\n",
    "# Example usage:\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "paragraphs = [\n",
    "    \n",
    "    \"He's at my place half the time and his fiance(e)'s place the other half of the time. He's been (homeless) couch surfing for several years and only recently got engaged to his other partner. We don't have any current issues that would lead me to want this arrangement to stop, but I do want to protect my own legal rights.\",\n",
    "    \"I don't think he, in particular, would do that, but I do want to retain my own legal rights wherever possible/appropriate.\",\n",
    "  \n",
    "]\n",
    "\n",
    "author_change = predict_author_change(model, paragraphs)\n",
    "print(\"Author change detected:\", author_change)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a582f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DONT RUN\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import pandas as pd\n",
    "\n",
    "# Load your DataFrame with the paragraphs (Replace 'df' with your DataFrame)\n",
    "df = pd.read_excel(\"output_data.xlsx\")  # Load your data\n",
    "\n",
    "# Sample 10% of your dataset\n",
    "sampled_df = df.sample(frac=0.1, random_state=42)  # Adjust the random state as needed\n",
    "\n",
    "# Initialize the Sentence Transformer model (you can use your own model)\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "# Function to predict author changes between paragraphs\n",
    "def predict_author_change(model, paragraphs):\n",
    "    # Ensure your model is in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Initialize a list to store the similarity scores\n",
    "    similarity_scores = []\n",
    "\n",
    "    # Loop through successive pairs of paragraphs\n",
    "    for i in range(1, len(paragraphs)):\n",
    "        # Encode the paragraphs using the model\n",
    "        passage1_embedding = model.encode(paragraphs[i - 1], convert_to_tensor=True)\n",
    "        passage2_embedding = model.encode(paragraphs[i], convert_to_tensor=True)\n",
    "\n",
    "        # Compute the cosine similarity between the embeddings\n",
    "        similarity = util.pytorch_cos_sim(passage1_embedding, passage2_embedding)\n",
    "        \n",
    "        # Append the similarity score to the list\n",
    "        similarity_scores.append(similarity.item())\n",
    "\n",
    "    # Define a threshold for change detection\n",
    "    threshold = 0.5  # You can adjust this threshold as needed\n",
    "\n",
    "    # Check if any of the similarity scores indicate a change of author\n",
    "    author_change = any(score < threshold for score in similarity_scores)\n",
    "\n",
    "    return author_change\n",
    "\n",
    "# Apply the prediction function to your sampled DataFrame\n",
    "predictions = []\n",
    "for index, row in sampled_df.iterrows():\n",
    "    paragraphs = row['splitted_text']  # Modify this based on your DataFrame column\n",
    "    author_change = predict_author_change(model, paragraphs)\n",
    "    predictions.append(author_change)\n",
    "\n",
    "# Add the predictions as a new column in your sampled DataFrame\n",
    "sampled_df['Predicted_Author_Change'] = predictions\n",
    "\n",
    "# You can save the updated DataFrame or further analyze the results as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2c93c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Post Number</th>\n",
       "      <th>JSON Data</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Changes</th>\n",
       "      <th>Text Data</th>\n",
       "      <th>splitted_text</th>\n",
       "      <th>Predicted_Author_Change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1743</th>\n",
       "      <td>1744</td>\n",
       "      <td>{'authors': 4, 'changes': [1, 1, 1, 1, 1]}</td>\n",
       "      <td>4</td>\n",
       "      <td>[1, 1, 1, 1, 1]</td>\n",
       "      <td>For so many years, decades even, russia has be...</td>\n",
       "      <td>['For so many years, decades even, russia has ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>2197</td>\n",
       "      <td>{'authors': 2, 'changes': [1]}</td>\n",
       "      <td>2</td>\n",
       "      <td>[1]</td>\n",
       "      <td>Now an archer can only aim at one target at a ...</td>\n",
       "      <td>['Now an archer can only aim at one target at ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1728</th>\n",
       "      <td>1729</td>\n",
       "      <td>{'authors': 2, 'changes': [0, 1]}</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>What the attorney means by this is that they'r...</td>\n",
       "      <td>[\"What the attorney means by this is that they...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3337</th>\n",
       "      <td>3338</td>\n",
       "      <td>{'authors': 4, 'changes': [1, 1, 1, 1, 1, 1, 1...</td>\n",
       "      <td>4</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 0, 1]</td>\n",
       "      <td>In general, be courteous to others. Debate/dis...</td>\n",
       "      <td>[\"In general, be courteous to others. Debate/d...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>299</td>\n",
       "      <td>{'authors': 2, 'changes': [1, 1]}</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>Schools all over the world will deny enrollmen...</td>\n",
       "      <td>['Schools all over the world will deny enrollm...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3949</th>\n",
       "      <td>3950</td>\n",
       "      <td>{'authors': 2, 'changes': [0, 1, 0]}</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>Can you explain? By headers I assume they mean...</td>\n",
       "      <td>['Can you explain? By headers I assume they me...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>175</td>\n",
       "      <td>{'authors': 4, 'changes': [1, 1, 1]}</td>\n",
       "      <td>4</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "      <td>Yep. Had a gun runner case a while back. He wa...</td>\n",
       "      <td>['Yep. Had a gun runner case a while back. He ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>394</td>\n",
       "      <td>{'authors': 2, 'changes': [0, 1]}</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>You can use the will to nominate a guardian. I...</td>\n",
       "      <td>['You can use the will to nominate a guardian....</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3721</th>\n",
       "      <td>3722</td>\n",
       "      <td>{'authors': 2, 'changes': [1, 0, 0, 1]}</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 0, 0, 1]</td>\n",
       "      <td>I am a bot, and this action was performed auto...</td>\n",
       "      <td>['I am a bot, and this action was performed au...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3713</th>\n",
       "      <td>3714</td>\n",
       "      <td>{'authors': 2, 'changes': [1]}</td>\n",
       "      <td>2</td>\n",
       "      <td>[1]</td>\n",
       "      <td>The claim made in the latter literature is, br...</td>\n",
       "      <td>['The claim made in the latter literature is, ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>420 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Post Number                                          JSON Data  Authors  \\\n",
       "1743         1744         {'authors': 4, 'changes': [1, 1, 1, 1, 1]}        4   \n",
       "2196         2197                     {'authors': 2, 'changes': [1]}        2   \n",
       "1728         1729                  {'authors': 2, 'changes': [0, 1]}        2   \n",
       "3337         3338  {'authors': 4, 'changes': [1, 1, 1, 1, 1, 1, 1...        4   \n",
       "298           299                  {'authors': 2, 'changes': [1, 1]}        2   \n",
       "...           ...                                                ...      ...   \n",
       "3949         3950               {'authors': 2, 'changes': [0, 1, 0]}        2   \n",
       "174           175               {'authors': 4, 'changes': [1, 1, 1]}        4   \n",
       "393           394                  {'authors': 2, 'changes': [0, 1]}        2   \n",
       "3721         3722            {'authors': 2, 'changes': [1, 0, 0, 1]}        2   \n",
       "3713         3714                     {'authors': 2, 'changes': [1]}        2   \n",
       "\n",
       "                          Changes  \\\n",
       "1743              [1, 1, 1, 1, 1]   \n",
       "2196                          [1]   \n",
       "1728                       [0, 1]   \n",
       "3337  [1, 1, 1, 1, 1, 1, 1, 0, 1]   \n",
       "298                        [1, 1]   \n",
       "...                           ...   \n",
       "3949                    [0, 1, 0]   \n",
       "174                     [1, 1, 1]   \n",
       "393                        [0, 1]   \n",
       "3721                 [1, 0, 0, 1]   \n",
       "3713                          [1]   \n",
       "\n",
       "                                              Text Data  \\\n",
       "1743  For so many years, decades even, russia has be...   \n",
       "2196  Now an archer can only aim at one target at a ...   \n",
       "1728  What the attorney means by this is that they'r...   \n",
       "3337  In general, be courteous to others. Debate/dis...   \n",
       "298   Schools all over the world will deny enrollmen...   \n",
       "...                                                 ...   \n",
       "3949  Can you explain? By headers I assume they mean...   \n",
       "174   Yep. Had a gun runner case a while back. He wa...   \n",
       "393   You can use the will to nominate a guardian. I...   \n",
       "3721  I am a bot, and this action was performed auto...   \n",
       "3713  The claim made in the latter literature is, br...   \n",
       "\n",
       "                                          splitted_text  \\\n",
       "1743  ['For so many years, decades even, russia has ...   \n",
       "2196  ['Now an archer can only aim at one target at ...   \n",
       "1728  [\"What the attorney means by this is that they...   \n",
       "3337  [\"In general, be courteous to others. Debate/d...   \n",
       "298   ['Schools all over the world will deny enrollm...   \n",
       "...                                                 ...   \n",
       "3949  ['Can you explain? By headers I assume they me...   \n",
       "174   ['Yep. Had a gun runner case a while back. He ...   \n",
       "393   ['You can use the will to nominate a guardian....   \n",
       "3721  ['I am a bot, and this action was performed au...   \n",
       "3713  ['The claim made in the latter literature is, ...   \n",
       "\n",
       "      Predicted_Author_Change  \n",
       "1743                     True  \n",
       "2196                     True  \n",
       "1728                     True  \n",
       "3337                     True  \n",
       "298                      True  \n",
       "...                       ...  \n",
       "3949                     True  \n",
       "174                      True  \n",
       "393                      True  \n",
       "3721                     True  \n",
       "3713                     True  \n",
       "\n",
       "[420 rows x 7 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sampled_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d32735b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import pandas as pd\n",
    "\n",
    "# Load your DataFrame with the paragraphs (Replace 'df' with your DataFrame)\n",
    "df = pd.read_excel(\"output_data.xlsx\")  # Load your data\n",
    "\n",
    "# Sample 10% of your dataset\n",
    "sampled_df = df.sample(frac=0.1, random_state=42)  # Adjust the random state as needed\n",
    "\n",
    "# Initialize the Sentence Transformer model (you can use your own model)\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "# Function to predict author changes between paragraphs\n",
    "def predict_author_change(model, paragraphs):\n",
    "    # Ensure your model is in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Initialize a list to store the similarity scores\n",
    "    similarity_scores = []\n",
    "\n",
    "    # Loop through successive pairs of paragraphs\n",
    "    for i in range(1, len(paragraphs)):\n",
    "        # Encode the paragraphs using the model\n",
    "        passage1_embedding = model.encode(paragraphs[i - 1], convert_to_tensor=True)\n",
    "        passage2_embedding = model.encode(paragraphs[i], convert_to_tensor=True)\n",
    "\n",
    "        # Compute the cosine similarity between the embeddings\n",
    "        similarity = util.pytorch_cos_sim(passage1_embedding, passage2_embedding)\n",
    "        \n",
    "        # Append the similarity score to the list\n",
    "        similarity_scores.append(similarity.item())\n",
    "\n",
    "    # Define a threshold for change detection\n",
    "    threshold = 0.5  # You can adjust this threshold as needed\n",
    "\n",
    "    # Check if any of the similarity scores indicate a change between paragraphs\n",
    "    author_changes = [score < threshold for score in similarity_scores]\n",
    "\n",
    "    return author_changes\n",
    "\n",
    "# Apply the prediction function to your sampled DataFrame\n",
    "predictions = []\n",
    "for index, row in sampled_df.iterrows():\n",
    "    paragraphs = row['splitted_text']  # Modify this based on your DataFrame column\n",
    "    author_changes = predict_author_change(model, paragraphs)\n",
    "    predictions.append(author_changes)\n",
    "\n",
    "# Add the predictions as a new column in your sampled DataFrame\n",
    "sampled_df['Predicted_Author_Changes'] = predictions\n",
    "\n",
    "# You can save the updated DataFrame or further analyze the results as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8ff34115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.40      0.40         5\n",
      "           1       0.40      0.40      0.40         5\n",
      "\n",
      "    accuracy                           0.40        10\n",
      "   macro avg       0.40      0.40      0.40        10\n",
      "weighted avg       0.40      0.40      0.40        10\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0a7bfed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def prediction_task3_threshold(model : SentenceTransformer, passages : List[str], threshold : float):\n",
    "    \"\"\"\n",
    "    Perform inference on a set of passages using the threshold approach\n",
    "    \"\"\"\n",
    "    embeddings = model.encode(passages, convert_to_tensor=True)\n",
    "\n",
    "    similarity_scores = []\n",
    "\n",
    "    for i in range(len(passages) - 1):\n",
    "        sim = util.cos_sim(embeddings[i], embeddings[i + 1])\n",
    "        similarity_scores.append(sim.item())\n",
    "\n",
    "    # Threshold\n",
    "    pred_changes = [1 if sim < threshold else 0 for sim in similarity_scores]\n",
    "    return pred_changes\n",
    "\n",
    "def evaluate_model_task3_threshold(model : SentenceTransformer, df : pd.DataFrame, threshold : float, save_pred_to_disk : str = None):\n",
    "    \"\"\"\n",
    "    Evaluate a SentenceTransformer encoder model using the task3 inference method with the threshold approach on a dataframe of examples\n",
    "    \"\"\"\n",
    "    valid_labels = []\n",
    "    y_preds = []\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        passages = row[\"splitted_text\"]\n",
    "\n",
    "        pred_authors = prediction_task3_threshold(model, passages, threshold)\n",
    "\n",
    "        valid_labels += row[\"changes\"]\n",
    "        y_preds += pred_authors\n",
    "\n",
    "    print(classification_report(valid_labels, y_preds))\n",
    "    if not save_pred_to_disk is None:\n",
    "        np.save(save_pred_to_disk, y_preds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a8e07c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ed2e344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been exported to data_with_paragraphs.xlsx\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91b06e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Post Number                                JSON Data  Authors  \\\n",
      "0               1        {'authors': 2, 'changes': [1, 0]}        2   \n",
      "1              10  {'authors': 3, 'changes': [1, 1, 0, 1]}        3   \n",
      "2             100     {'authors': 3, 'changes': [1, 1, 1]}        3   \n",
      "3            1000           {'authors': 2, 'changes': [1]}        2   \n",
      "4            1001     {'authors': 4, 'changes': [1, 1, 1]}        4   \n",
      "...           ...                                      ...      ...   \n",
      "4195          995        {'authors': 2, 'changes': [1, 1]}        2   \n",
      "4196          996           {'authors': 2, 'changes': [1]}        2   \n",
      "4197          997     {'authors': 4, 'changes': [1, 1, 1]}        4   \n",
      "4198          998        {'authors': 3, 'changes': [1, 1]}        3   \n",
      "4199          999        {'authors': 3, 'changes': [1, 1]}        3   \n",
      "\n",
      "           Changes                                          Text Data  \\\n",
      "0           [1, 0]  I'm not arguing with you here, I'm simply tryi...   \n",
      "1     [1, 1, 0, 1]  Biden has the power to write an executive orde...   \n",
      "2        [1, 1, 1]  In general, be courteous to others. Debate/dis...   \n",
      "3              [1]  Second, until late in the 20th century, the Ot...   \n",
      "4        [1, 1, 1]  Arming and supplying a generation of hostile y...   \n",
      "...            ...                                                ...   \n",
      "4195        [1, 1]  Yeah fair enough, I kind of figured I was prob...   \n",
      "4196           [1]  No need for more suffering. Being a russian is...   \n",
      "4197     [1, 1, 1]  - - - - - - - - - - - - - - - - - - - - - - - ...   \n",
      "4198        [1, 1]  Kanye is being manipulated and taken advantage...   \n",
      "4199        [1, 1]  It appears you forgot to include your location...   \n",
      "\n",
      "                                        Paragraphs List  \n",
      "0     [I'm not arguing with you here, I'm simply try...  \n",
      "1     [Biden has the power to write an executive ord...  \n",
      "2     [In general, be courteous to others. Debate/di...  \n",
      "3     [Second, until late in the 20th century, the O...  \n",
      "4     [Arming and supplying a generation of hostile ...  \n",
      "...                                                 ...  \n",
      "4195  [Yeah fair enough, I kind of figured I was pro...  \n",
      "4196  [No need for more suffering. Being a russian i...  \n",
      "4197  [- - - - - - - - - - - - - - - - - - - - - - -...  \n",
      "4198  [Kanye is being manipulated and taken advantag...  \n",
      "4199  [It appears you forgot to include your locatio...  \n",
      "\n",
      "[4200 rows x 6 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Post Number</th>\n",
       "      <th>JSON Data</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Changes</th>\n",
       "      <th>Text Data</th>\n",
       "      <th>Paragraphs List</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>{'authors': 2, 'changes': [1, 0]}</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>I'm not arguing with you here, I'm simply tryi...</td>\n",
       "      <td>[I'm not arguing with you here, I'm simply try...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>{'authors': 3, 'changes': [1, 1, 0, 1]}</td>\n",
       "      <td>3</td>\n",
       "      <td>[1, 1, 0, 1]</td>\n",
       "      <td>Biden has the power to write an executive orde...</td>\n",
       "      <td>[Biden has the power to write an executive ord...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>{'authors': 3, 'changes': [1, 1, 1]}</td>\n",
       "      <td>3</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "      <td>In general, be courteous to others. Debate/dis...</td>\n",
       "      <td>[In general, be courteous to others. Debate/di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>{'authors': 2, 'changes': [1]}</td>\n",
       "      <td>2</td>\n",
       "      <td>[1]</td>\n",
       "      <td>Second, until late in the 20th century, the Ot...</td>\n",
       "      <td>[Second, until late in the 20th century, the O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001</td>\n",
       "      <td>{'authors': 4, 'changes': [1, 1, 1]}</td>\n",
       "      <td>4</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "      <td>Arming and supplying a generation of hostile y...</td>\n",
       "      <td>[Arming and supplying a generation of hostile ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Post Number                                JSON Data  Authors  \\\n",
       "0            1        {'authors': 2, 'changes': [1, 0]}        2   \n",
       "1           10  {'authors': 3, 'changes': [1, 1, 0, 1]}        3   \n",
       "2          100     {'authors': 3, 'changes': [1, 1, 1]}        3   \n",
       "3         1000           {'authors': 2, 'changes': [1]}        2   \n",
       "4         1001     {'authors': 4, 'changes': [1, 1, 1]}        4   \n",
       "\n",
       "        Changes                                          Text Data  \\\n",
       "0        [1, 0]  I'm not arguing with you here, I'm simply tryi...   \n",
       "1  [1, 1, 0, 1]  Biden has the power to write an executive orde...   \n",
       "2     [1, 1, 1]  In general, be courteous to others. Debate/dis...   \n",
       "3           [1]  Second, until late in the 20th century, the Ot...   \n",
       "4     [1, 1, 1]  Arming and supplying a generation of hostile y...   \n",
       "\n",
       "                                     Paragraphs List  \n",
       "0  [I'm not arguing with you here, I'm simply try...  \n",
       "1  [Biden has the power to write an executive ord...  \n",
       "2  [In general, be courteous to others. Debate/di...  \n",
       "3  [Second, until late in the 20th century, the O...  \n",
       "4  [Arming and supplying a generation of hostile ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5c2fc80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7452380952380953\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.03      0.06       219\n",
      "           1       1.00      1.00      1.00       840\n",
      "\n",
      "   micro avg       1.00      0.80      0.89      1059\n",
      "   macro avg       0.89      0.52      0.53      1059\n",
      "weighted avg       0.95      0.80      0.81      1059\n",
      " samples avg       1.00      0.87      0.92      1059\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6ed98b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dee59ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Post Number  Paragraph Number  \\\n",
      "0            1                 1   \n",
      "1            1                 2   \n",
      "2            2                 1   \n",
      "3            2                 2   \n",
      "4            2                 3   \n",
      "\n",
      "                                      Paragraph Text  Authors  Label  \n",
      "0  I'm not arguing with you here, I'm simply tryi...        2      1  \n",
      "1  He's at my place half the time and his fiance(...        2      0  \n",
      "2  Biden has the power to write an executive orde...        3      1  \n",
      "3  r/politics is currently accepting new moderato...        3      1  \n",
      "4  The inflation reduction act increases inflatio...        3      0  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Post Number</th>\n",
       "      <th>Paragraph Number</th>\n",
       "      <th>Paragraph Text</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>I'm not arguing with you here, I'm simply tryi...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>He's at my place half the time and his fiance(...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Biden has the power to write an executive orde...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>r/politics is currently accepting new moderato...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>The inflation reduction act increases inflatio...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>There is really only one solution that is work...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>In general, be courteous to others. Debate/dis...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Are you any of these? If so, then don't be so ...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>r/politics is currently accepting new moderato...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Second, until late in the 20th century, the Ot...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Arming and supplying a generation of hostile y...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>Technically, yes. But unfortunately, â€œtechnica...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Hostile territory, essentially. Mines, shellin...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>For years I offered to make arrangements ahead...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>Since itâ€™s apple, he has an iCloud account. If...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Post Number  Paragraph Number  \\\n",
       "0             1                 1   \n",
       "1             1                 2   \n",
       "2             2                 1   \n",
       "3             2                 2   \n",
       "4             2                 3   \n",
       "5             2                 4   \n",
       "6             3                 1   \n",
       "7             3                 2   \n",
       "8             3                 3   \n",
       "9             4                 1   \n",
       "10            5                 1   \n",
       "11            5                 2   \n",
       "12            5                 3   \n",
       "13            6                 1   \n",
       "14            6                 2   \n",
       "\n",
       "                                       Paragraph Text  Authors  Label  \n",
       "0   I'm not arguing with you here, I'm simply tryi...        2      1  \n",
       "1   He's at my place half the time and his fiance(...        2      0  \n",
       "2   Biden has the power to write an executive orde...        3      1  \n",
       "3   r/politics is currently accepting new moderato...        3      1  \n",
       "4   The inflation reduction act increases inflatio...        3      0  \n",
       "5   There is really only one solution that is work...        3      1  \n",
       "6   In general, be courteous to others. Debate/dis...        3      1  \n",
       "7   Are you any of these? If so, then don't be so ...        3      1  \n",
       "8   r/politics is currently accepting new moderato...        3      1  \n",
       "9   Second, until late in the 20th century, the Ot...        2      1  \n",
       "10  Arming and supplying a generation of hostile y...        4      1  \n",
       "11  Technically, yes. But unfortunately, â€œtechnica...        4      1  \n",
       "12  Hostile territory, essentially. Mines, shellin...        4      1  \n",
       "13  For years I offered to make arrangements ahead...        2      1  \n",
       "14  Since itâ€™s apple, he has an iCloud account. If...        2      1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9333d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Number\tParagraph Number\tParagraph Text\tAuthors\tLabel\n",
      "   Post Number  Paragraph Number  \\\n",
      "0            1                 1   \n",
      "1            1                 2   \n",
      "2            2                 1   \n",
      "3            2                 2   \n",
      "4            2                 3   \n",
      "\n",
      "                                      Paragraph Text  Authors  Label  \n",
      "0  I'm not arguing with you here, I'm simply tryi...        2      0  \n",
      "1  He's at my place half the time and his fiance(...        2      1  \n",
      "2  Biden has the power to write an executive orde...        3      0  \n",
      "3  r/politics is currently accepting new moderato...        3      1  \n",
      "4  The inflation reduction act increases inflatio...        3      1  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Post Number</th>\n",
       "      <th>Paragraph Number</th>\n",
       "      <th>Paragraph Text</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>I'm not arguing with you here, I'm simply tryi...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>He's at my place half the time and his fiance(...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Biden has the power to write an executive orde...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>r/politics is currently accepting new moderato...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>The inflation reduction act increases inflatio...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>There is really only one solution that is work...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>In general, be courteous to others. Debate/dis...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Are you any of these? If so, then don't be so ...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>r/politics is currently accepting new moderato...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Second, until late in the 20th century, the Ot...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Arming and supplying a generation of hostile y...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>Technically, yes. But unfortunately, â€œtechnica...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Hostile territory, essentially. Mines, shellin...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>For years I offered to make arrangements ahead...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>Since itâ€™s apple, he has an iCloud account. If...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Post Number  Paragraph Number  \\\n",
       "0             1                 1   \n",
       "1             1                 2   \n",
       "2             2                 1   \n",
       "3             2                 2   \n",
       "4             2                 3   \n",
       "5             2                 4   \n",
       "6             3                 1   \n",
       "7             3                 2   \n",
       "8             3                 3   \n",
       "9             4                 1   \n",
       "10            5                 1   \n",
       "11            5                 2   \n",
       "12            5                 3   \n",
       "13            6                 1   \n",
       "14            6                 2   \n",
       "\n",
       "                                       Paragraph Text  Authors  Label  \n",
       "0   I'm not arguing with you here, I'm simply tryi...        2      0  \n",
       "1   He's at my place half the time and his fiance(...        2      1  \n",
       "2   Biden has the power to write an executive orde...        3      0  \n",
       "3   r/politics is currently accepting new moderato...        3      1  \n",
       "4   The inflation reduction act increases inflatio...        3      1  \n",
       "5   There is really only one solution that is work...        3      0  \n",
       "6   In general, be courteous to others. Debate/dis...        3      0  \n",
       "7   Are you any of these? If so, then don't be so ...        3      1  \n",
       "8   r/politics is currently accepting new moderato...        3      1  \n",
       "9   Second, until late in the 20th century, the Ot...        2      0  \n",
       "10  Arming and supplying a generation of hostile y...        4      0  \n",
       "11  Technically, yes. But unfortunately, â€œtechnica...        4      1  \n",
       "12  Hostile territory, essentially. Mines, shellin...        4      1  \n",
       "13  For years I offered to make arrangements ahead...        2      0  \n",
       "14  Since itâ€™s apple, he has an iCloud account. If...        2      1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29ffe068",
   "metadata": {},
   "source": [
    "PROCESSING WITH LABELS CORRECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a376239a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Number\tParagraph Number\tParagraph Text\tAuthors\tLabel\n",
      "   Post Number  Paragraph Number  \\\n",
      "0            1                 1   \n",
      "1            1                 2   \n",
      "2            1                 3   \n",
      "3            2                 1   \n",
      "4            2                 2   \n",
      "\n",
      "                                      Paragraph Text  Authors  Label  \n",
      "0  I'm not arguing with you here, I'm simply tryi...        2      0  \n",
      "1  He's at my place half the time and his fiance(...        2      1  \n",
      "2  I don't think he, in particular, would do that...        2      0  \n",
      "3  Biden has the power to write an executive orde...        3      0  \n",
      "4  r/politics is currently accepting new moderato...        3      1  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Post Number</th>\n",
       "      <th>Paragraph Number</th>\n",
       "      <th>Paragraph Text</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>I'm not arguing with you here, I'm simply tryi...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>He's at my place half the time and his fiance(...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>I don't think he, in particular, would do that...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Biden has the power to write an executive orde...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>r/politics is currently accepting new moderato...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>The inflation reduction act increases inflatio...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>There is really only one solution that is work...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>You arenâ€™t given unrealistic expectations to p...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>In general, be courteous to others. Debate/dis...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Are you any of these? If so, then don't be so ...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>r/politics is currently accepting new moderato...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>It looks to somewhat mirror the situation that...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Second, until late in the 20th century, the Ot...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>I'm not sure if that is the same thing. Turkom...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Arming and supplying a generation of hostile y...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Post Number  Paragraph Number  \\\n",
       "0             1                 1   \n",
       "1             1                 2   \n",
       "2             1                 3   \n",
       "3             2                 1   \n",
       "4             2                 2   \n",
       "5             2                 3   \n",
       "6             2                 4   \n",
       "7             2                 5   \n",
       "8             3                 1   \n",
       "9             3                 2   \n",
       "10            3                 3   \n",
       "11            3                 4   \n",
       "12            4                 1   \n",
       "13            4                 2   \n",
       "14            5                 1   \n",
       "\n",
       "                                       Paragraph Text  Authors  Label  \n",
       "0   I'm not arguing with you here, I'm simply tryi...        2      0  \n",
       "1   He's at my place half the time and his fiance(...        2      1  \n",
       "2   I don't think he, in particular, would do that...        2      0  \n",
       "3   Biden has the power to write an executive orde...        3      0  \n",
       "4   r/politics is currently accepting new moderato...        3      1  \n",
       "5   The inflation reduction act increases inflatio...        3      1  \n",
       "6   There is really only one solution that is work...        3      0  \n",
       "7   You arenâ€™t given unrealistic expectations to p...        3      1  \n",
       "8   In general, be courteous to others. Debate/dis...        3      0  \n",
       "9   Are you any of these? If so, then don't be so ...        3      1  \n",
       "10  r/politics is currently accepting new moderato...        3      1  \n",
       "11  It looks to somewhat mirror the situation that...        3      1  \n",
       "12  Second, until late in the 20th century, the Ot...        2      0  \n",
       "13  I'm not sure if that is the same thing. Turkom...        2      1  \n",
       "14  Arming and supplying a generation of hostile y...        4      0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9075d257",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60f63b70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f995960c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17104 entries, 0 to 17103\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   Post Number       17104 non-null  int64 \n",
      " 1   Paragraph Number  17104 non-null  int64 \n",
      " 2   Paragraph Text    17104 non-null  object\n",
      " 3   Authors           17104 non-null  int64 \n",
      " 4   Label             17104 non-null  int64 \n",
      "dtypes: int64(4), object(1)\n",
      "memory usage: 668.2+ KB\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3909dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (0.15.2)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (2.0.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from torchvision) (1.23.5)\n",
      "Requirement already satisfied: requests in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from requests->torchvision) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from requests->torchvision) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from sympy->torch) (1.2.1)\n",
      "Requirement already satisfied: transformers in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (4.34.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (0.17.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (22.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: datasets in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (2.14.5)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from datasets) (1.23.5)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from datasets) (13.0.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from datasets) (2.28.1)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from datasets) (4.64.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec<2023.9.0,>=2023.1.0 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from fsspec[http]<2023.9.0,>=2023.1.0->datasets) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from datasets) (3.8.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from datasets) (0.17.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from datasets) (22.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from pandas->datasets) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting simpletransformers\n",
      "  Downloading simpletransformers-0.64.3-py3-none-any.whl.metadata (42 kB)\n",
      "     ---------------------------------------- 0.0/42.3 kB ? eta -:--:--\n",
      "     ---------------------------------------- 42.3/42.3 kB 2.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from simpletransformers) (1.23.5)\n",
      "Requirement already satisfied: requests in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from simpletransformers) (2.28.1)\n",
      "Requirement already satisfied: tqdm>=4.47.0 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from simpletransformers) (4.64.1)\n",
      "Requirement already satisfied: regex in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from simpletransformers) (2022.7.9)\n",
      "Requirement already satisfied: transformers>=4.31.0 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from simpletransformers) (4.34.0)\n",
      "Requirement already satisfied: datasets in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from simpletransformers) (2.14.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from simpletransformers) (1.10.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from simpletransformers) (1.2.1)\n",
      "Collecting seqeval (from simpletransformers)\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "     ---------------------------------------- 0.0/43.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 43.6/43.6 kB 2.2 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: tensorboard in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from simpletransformers) (2.13.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from simpletransformers) (1.5.3)\n",
      "Requirement already satisfied: tokenizers in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from simpletransformers) (0.14.1)\n",
      "Collecting wandb>=0.10.32 (from simpletransformers)\n",
      "  Downloading wandb-0.15.12-py3-none-any.whl.metadata (9.8 kB)\n",
      "Collecting streamlit (from simpletransformers)\n",
      "  Downloading streamlit-1.28.0-py2.py3-none-any.whl.metadata (8.1 kB)\n",
      "Collecting sentencepiece (from simpletransformers)\n",
      "  Downloading sentencepiece-0.1.99-cp310-cp310-win_amd64.whl (977 kB)\n",
      "     ---------------------------------------- 0.0/977.5 kB ? eta -:--:--\n",
      "     --- ---------------------------------- 102.4/977.5 kB 2.9 MB/s eta 0:00:01\n",
      "     -------------- ----------------------- 368.6/977.5 kB 4.6 MB/s eta 0:00:01\n",
      "     ------------------------ ------------- 624.6/977.5 kB 4.9 MB/s eta 0:00:01\n",
      "     --------------------------- ---------- 696.3/977.5 kB 4.9 MB/s eta 0:00:01\n",
      "     -------------------------------------  972.8/977.5 kB 4.7 MB/s eta 0:00:01\n",
      "     -------------------------------------- 977.5/977.5 kB 4.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from tqdm>=4.47.0->simpletransformers) (0.4.6)\n",
      "Requirement already satisfied: filelock in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers>=4.31.0->simpletransformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers>=4.31.0->simpletransformers) (0.17.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers>=4.31.0->simpletransformers) (22.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers>=4.31.0->simpletransformers) (6.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers>=4.31.0->simpletransformers) (0.4.0)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from wandb>=0.10.32->simpletransformers) (8.0.4)\n",
      "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb>=0.10.32->simpletransformers)\n",
      "  Downloading GitPython-3.1.40-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: psutil>=5.0.0 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from wandb>=0.10.32->simpletransformers) (5.9.0)\n",
      "Collecting sentry-sdk>=1.0.0 (from wandb>=0.10.32->simpletransformers)\n",
      "  Downloading sentry_sdk-1.34.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb>=0.10.32->simpletransformers)\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Collecting pathtools (from wandb>=0.10.32->simpletransformers)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: HTTP error 403 while getting https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz (from https://pypi.org/simple/pathtools/)\n",
      "ERROR: Could not install requirement pathtools from https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz (from wandb>=0.10.32->simpletransformers) because of HTTP error 403 Client Error: Forbidden for url: https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz for URL https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz (from https://pypi.org/simple/pathtools/)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plotly in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (5.9.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from plotly) (8.0.1)\n",
      "Requirement already satisfied: accelerate in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (0.23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from accelerate) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from accelerate) (22.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from accelerate) (6.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from accelerate) (2.0.1)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from accelerate) (0.17.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (4.4.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from huggingface-hub->accelerate) (2023.6.0)\n",
      "Requirement already satisfied: requests in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from huggingface-hub->accelerate) (2.28.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from huggingface-hub->accelerate) (4.64.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from requests->huggingface-hub->accelerate) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from sympy->torch>=1.10.0->accelerate) (1.2.1)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1502722f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (23.2.1)\n",
      "Collecting pip\n",
      "  Obtaining dependency information for pip from https://files.pythonhosted.org/packages/47/6a/453160888fab7c6a432a6e25f8afe6256d0d9f2cbd25971021da6491d899/pip-23.3.1-py3-none-any.whl.metadata\n",
      "  Downloading pip-23.3.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Downloading pip-23.3.1-py3-none-any.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.2/2.1 MB 3.1 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 0.5/2.1 MB 5.0 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.7/2.1 MB 4.6 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.7/2.1 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.2/2.1 MB 4.9 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.3/2.1 MB 4.9 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.3/2.1 MB 4.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.7/2.1 MB 4.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.9/2.1 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 4.6 MB/s eta 0:00:00\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 23.2.1\n",
      "    Uninstalling pip-23.2.1:\n",
      "      Successfully uninstalled pip-23.2.1\n",
      "Successfully installed pip-23.3.1\n",
      "Requirement already satisfied: transformers in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (4.34.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (0.17.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (22.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: torch in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (0.15.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from torchvision) (1.23.5)\n",
      "Requirement already satisfied: requests in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from requests->torchvision) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from requests->torchvision) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from sympy->torch) (1.2.1)\n",
      "Requirement already satisfied: torch in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\ebrahimr2\\appdata\\local\\anaconda3\\lib\\site-packages (from sympy->torch) (1.2.1)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ea3ca5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45082f22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2fd99ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DefaultVerifyPaths(cafile=None, capath=None, openssl_cafile_env='SSL_CERT_FILE', openssl_cafile='C:\\\\Program Files\\\\Common Files\\\\ssl/cert.pem', openssl_capath_env='SSL_CERT_DIR', openssl_capath='C:\\\\Program Files\\\\Common Files\\\\ssl/certs')\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d79a4b2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9df072d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f23b8ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b4f54daf38b45b7893cac5dc10e6a11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EBRAHIMR2\\AppData\\Local\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:137: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\EBRAHIMR2\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6d4150",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1ff8c15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d7960e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15eba2b89b264d4883da49662ccccee2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11972 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19194dd485b64a3594f640ed4e9c6ecb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5132 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "518141f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fafe5c86a474900a0ca2b0cfb823d80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/17.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca543cb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c425a53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "558e8b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d0f65b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The model did not return a loss from the inputs, only the following keys: logits. For reference, the inputs it received are input_ids,token_type_ids,attention_mask.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m## Now we train the Sequence classifier. be patient this may take a while\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\transformers\\trainer.py:1591\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1589\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   1590\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1591\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1592\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1594\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1596\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\transformers\\trainer.py:1892\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1889\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m   1891\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[1;32m-> 1892\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1895\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   1896\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[0;32m   1897\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   1898\u001b[0m ):\n\u001b[0;32m   1899\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   1900\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\transformers\\trainer.py:2776\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   2773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m   2775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[1;32m-> 2776\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mn_gpu \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   2779\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()  \u001b[38;5;66;03m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\transformers\\trainer.py:2818\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[1;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[0;32m   2816\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2817\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m outputs:\n\u001b[1;32m-> 2818\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2819\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe model did not return a loss from the inputs, only the following keys: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2820\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(outputs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. For reference, the inputs it received are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(inputs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2821\u001b[0m         )\n\u001b[0;32m   2822\u001b[0m     \u001b[38;5;66;03m# We don't use .loss here since the model may return tuples instead of ModelOutput.\u001b[39;00m\n\u001b[0;32m   2823\u001b[0m     loss \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m outputs[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: The model did not return a loss from the inputs, only the following keys: logits. For reference, the inputs it received are input_ids,token_type_ids,attention_mask."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2ca4797e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame exported to C:\\Users\\EBRAHIMR2\\Downloads\\Data Science Masters\\Modules\\COS 801\\pan23-multi-author-analysis-dataset1\\pan23-multi-author-analysis-dataset1-train\\output.xlsx\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2808ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "472e65ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Post Number</th>\n",
       "      <th>Paragraph Number</th>\n",
       "      <th>Paragraph Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>I'm not arguing with you here, I'm simply tryi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>He's at my place half the time and his fiance(...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>I don't think he, in particular, would do that...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Biden has the power to write an executive orde...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>r/politics is currently accepting new moderato...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Post Number  Paragraph Number  \\\n",
       "0            1                 1   \n",
       "1            1                 2   \n",
       "2            1                 3   \n",
       "3            2                 1   \n",
       "4            2                 2   \n",
       "\n",
       "                                      Paragraph Text  Label  \n",
       "0  I'm not arguing with you here, I'm simply tryi...      1  \n",
       "1  He's at my place half the time and his fiance(...      1  \n",
       "2  I don't think he, in particular, would do that...      1  \n",
       "3  Biden has the power to write an executive orde...      1  \n",
       "4  r/politics is currently accepting new moderato...      1  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "094fbfa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6255b8bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Post Number</th>\n",
       "      <th>Paragraph Number</th>\n",
       "      <th>Paragraph Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>I'm not arguing with you here, I'm simply tryi...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>He's at my place half the time and his fiance(...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>I don't think he, in particular, would do that...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Biden has the power to write an executive orde...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>r/politics is currently accepting new moderato...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Post Number  Paragraph Number  \\\n",
       "0            1                 1   \n",
       "1            1                 2   \n",
       "2            1                 3   \n",
       "3            2                 1   \n",
       "4            2                 2   \n",
       "\n",
       "                                      Paragraph Text  Label  \n",
       "0  I'm not arguing with you here, I'm simply tryi...    1.0  \n",
       "1  He's at my place half the time and his fiance(...    NaN  \n",
       "2  I don't think he, in particular, would do that...    NaN  \n",
       "3  Biden has the power to write an executive orde...    1.0  \n",
       "4  r/politics is currently accepting new moderato...    NaN  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "008eb9e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Post Number</th>\n",
       "      <th>Paragraph Number</th>\n",
       "      <th>Paragraph Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>Changes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>I'm not arguing with you here, I'm simply tryi...</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>He's at my place half the time and his fiance(...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>I don't think he, in particular, would do that...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Biden has the power to write an executive orde...</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>r/politics is currently accepting new moderato...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Post Number  Paragraph Number  \\\n",
       "0            1                 1   \n",
       "1            1                 2   \n",
       "2            1                 3   \n",
       "3            2                 1   \n",
       "4            2                 2   \n",
       "\n",
       "                                      Paragraph Text  Label Changes  \n",
       "0  I'm not arguing with you here, I'm simply tryi...      1    None  \n",
       "1  He's at my place half the time and his fiance(...      0    None  \n",
       "2  I don't think he, in particular, would do that...      0    None  \n",
       "3  Biden has the power to write an executive orde...      1    None  \n",
       "4  r/politics is currently accepting new moderato...      0    None  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745c606a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5cba6b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1 Paragraphs:\n",
      "Paragraph 1:\n",
      "I'm not arguing with you here, I'm simply trying to contextualize this for you. To the extent that they are there, it is with your consent. The state has passed laws making sure that vulnerable people (not saying he's one) don't get abused (not saying you're abusing him), and in casting a wide net to save as many vulnerable little birds as possible from hitting the floor after being kicked out of their nest wrongfully, the state has (as much from a lack of better options as from any other reason) created a circumstance where occasionally some not-so-vulnerable little bird can take advantage of someone else's nest.\n",
      "He's at my place half the time and his fiance(e)'s place the other half of the time. He's been (homeless) couch surfing for several years and only recently got engaged to his other partner. We don't have any current issues that would lead me to want this arrangement to stop, but I do want to protect my own legal rights.\n",
      "I don't think he, in particular, would do that, but I do want to retain my own legal rights wherever possible/appropriate.\n",
      "--------------------------------------------------\n",
      "Entire Text:\n",
      "I'm not arguing with you here, I'm simply trying to contextualize this for you. To the extent that they are there, it is with your consent. The state has passed laws making sure that vulnerable people (not saying he's one) don't get abused (not saying you're abusing him), and in casting a wide net to save as many vulnerable little birds as possible from hitting the floor after being kicked out of their nest wrongfully, the state has (as much from a lack of better options as from any other reason) created a circumstance where occasionally some not-so-vulnerable little bird can take advantage of someone else's nest.\n",
      "He's at my place half the time and his fiance(e)'s place the other half of the time. He's been (homeless) couch surfing for several years and only recently got engaged to his other partner. We don't have any current issues that would lead me to want this arrangement to stop, but I do want to protect my own legal rights.\n",
      "I don't think he, in particular, would do that, but I do want to retain my own legal rights wherever possible/appropriate.\n",
      "====================================================================================================\n",
      "Document 2 Paragraphs:\n",
      "Paragraph 1:\n",
      "Biden has the power to write an executive order for anything he chooses. The issue is it winding up in the courts and being challenged, not him issuing an executing order.\n",
      "r/politics is currently accepting new moderator applications. If you want to help make this community a better place, consider !\n",
      "The inflation reduction act increases inflation. Constant economic growth is the opposite of what you would want if you were concerned about climate change. You would want a reduction of economic growth, a reduction of population size.\n",
      "There is really only one solution that is workable for the U.S., for mankind as a whole, and that is to reduce our population. In the last 50-70 years the U.S. has doubled. In that same time period the world has more than tripled in size. You want to know what is going to happen in the next 50-70 years if growth rates do not reverse themselves?\n",
      "You arenâ€™t given unrealistic expectations to produce either. Driving new marketing and growth opportunities is your job not mine.\n",
      "--------------------------------------------------\n",
      "Entire Text:\n",
      "Biden has the power to write an executive order for anything he chooses. The issue is it winding up in the courts and being challenged, not him issuing an executing order.\n",
      "r/politics is currently accepting new moderator applications. If you want to help make this community a better place, consider !\n",
      "The inflation reduction act increases inflation. Constant economic growth is the opposite of what you would want if you were concerned about climate change. You would want a reduction of economic growth, a reduction of population size.\n",
      "There is really only one solution that is workable for the U.S., for mankind as a whole, and that is to reduce our population. In the last 50-70 years the U.S. has doubled. In that same time period the world has more than tripled in size. You want to know what is going to happen in the next 50-70 years if growth rates do not reverse themselves?\n",
      "You arenâ€™t given unrealistic expectations to produce either. Driving new marketing and growth opportunities is your job not mine.\n",
      "====================================================================================================\n",
      "Document 3 Paragraphs:\n",
      "Paragraph 1:\n",
      "In general, be courteous to others. Debate/discuss/argue the merits of ideas, don't attack people. Personal insults, shill or troll accusations, hate speech, any suggestion or support of harm, violence, or death, and other rule violations can result in a permanent ban.\n",
      "Are you any of these? If so, then don't be so surprised that I, and I suspect most people, aren't so sympathetic to your \"plight\".\n",
      "r/politics is currently accepting new moderator applications. If you want to help make this community a better place, consider !\n",
      "It looks to somewhat mirror the situation that already occurs if a high net worth person renounces their US citizenship or non-citizen residency - they can stop accruing new US tax obligations by doing that, but first they have to pay taxes on the appreciation in value that occurred while they were a citizen or resident (in effect the taxes that would be due if they sold the assets they day they left the US tax system). There's a high minimum before that kicks in though.\n",
      "--------------------------------------------------\n",
      "Entire Text:\n",
      "In general, be courteous to others. Debate/discuss/argue the merits of ideas, don't attack people. Personal insults, shill or troll accusations, hate speech, any suggestion or support of harm, violence, or death, and other rule violations can result in a permanent ban.\n",
      "Are you any of these? If so, then don't be so surprised that I, and I suspect most people, aren't so sympathetic to your \"plight\".\n",
      "r/politics is currently accepting new moderator applications. If you want to help make this community a better place, consider !\n",
      "It looks to somewhat mirror the situation that already occurs if a high net worth person renounces their US citizenship or non-citizen residency - they can stop accruing new US tax obligations by doing that, but first they have to pay taxes on the appreciation in value that occurred while they were a citizen or resident (in effect the taxes that would be due if they sold the assets they day they left the US tax system). There's a high minimum before that kicks in though.\n",
      "====================================================================================================\n",
      "Document 4 Paragraphs:\n",
      "Paragraph 1:\n",
      "Second, until late in the 20th century, the Ottoman state did not aim to assimilate or Turkify its population. Nations are not as novel as some historians and social scientists assume, and it is beyond doubt that the Ottoman elites who were of Turkish origin had an idea about what being a Turk meant. Yet, the understanding of nationalism differs quite starkly from age to age. The 20th-century tendency of solidifying a country's internal cohesion by assimilating minorities did not seem to have crossed the minds of Ottomans for the majority of their history. The Greek conversion to Islam and 'Turkishness', of which we still know too little, during and after the Conquest of Anatolia by the Seljuk Turks seems to have been an automatic process rather than a conscious effort by Turks to convert Greeks. The same applies to Albanian Muslims, Bosnians, and Pomaks in the Balkans. And even these do not speak Turkish, despite identifying as 'Turkish' in the 20th century and their culture displaying a marked influence of Turkish. Even the term 'Turkish' as used by them amounted to nothing more than 'Muslim'. Hence, no 'converted' population or 'Turkish enclaves' in the old Ottoman Empire. The extent of 'Ottoman colonialism' is still a subject of debate among historians, but I think everyone would agree that Turkification is a much more limited and later phenomenon when compared to Europeanisation that came with European colonialism.\n",
      "I'm not sure if that is the same thing. Turkomans in Syria and Iraq is more because of the border-gore that happened after WW1. It doesn't really address the issue why there are no significant enclaves in Egypt or Jordan.\n",
      "--------------------------------------------------\n",
      "Entire Text:\n",
      "Second, until late in the 20th century, the Ottoman state did not aim to assimilate or Turkify its population. Nations are not as novel as some historians and social scientists assume, and it is beyond doubt that the Ottoman elites who were of Turkish origin had an idea about what being a Turk meant. Yet, the understanding of nationalism differs quite starkly from age to age. The 20th-century tendency of solidifying a country's internal cohesion by assimilating minorities did not seem to have crossed the minds of Ottomans for the majority of their history. The Greek conversion to Islam and 'Turkishness', of which we still know too little, during and after the Conquest of Anatolia by the Seljuk Turks seems to have been an automatic process rather than a conscious effort by Turks to convert Greeks. The same applies to Albanian Muslims, Bosnians, and Pomaks in the Balkans. And even these do not speak Turkish, despite identifying as 'Turkish' in the 20th century and their culture displaying a marked influence of Turkish. Even the term 'Turkish' as used by them amounted to nothing more than 'Muslim'. Hence, no 'converted' population or 'Turkish enclaves' in the old Ottoman Empire. The extent of 'Ottoman colonialism' is still a subject of debate among historians, but I think everyone would agree that Turkification is a much more limited and later phenomenon when compared to Europeanisation that came with European colonialism.\n",
      "I'm not sure if that is the same thing. Turkomans in Syria and Iraq is more because of the border-gore that happened after WW1. It doesn't really address the issue why there are no significant enclaves in Egypt or Jordan.\n",
      "====================================================================================================\n",
      "Document 5 Paragraphs:\n",
      "Paragraph 1:\n",
      "Arming and supplying a generation of hostile youth whose land you invaded, in an area of land your being pushed out of, by the countryman of those you plan to arm... what could possibly go wrong?! Operation: Let's lose faster?\n",
      "Technically, yes. But unfortunately, â€œtechnicallyâ€ doesnâ€™t mean a lot in international diplomacy. I wrote another brief comment here about why â€œyes, it isâ€, but also why â€œyes, but who cares.â€.\n",
      "Hostile territory, essentially. Mines, shelling, drones, just angry Ukrainians with guns (assuming these kids have no white flag above their heads, but even then, its not always going to save them, especially since russhists used white flag for deception). Lack of food and heating will not help them either. And if they are unlucky, they will have squads nearby formed specifically to prevent them from escaping. Either they'll be captured or killed.\n",
      "Bahaha. Clearly, you've never tried putting a 5-year-old to bed. You may think \"case closed, \" but you've forgotten the water break, the pee break, the \"I don't like this color of night light\" get up, the whole recollection of their day to only be recited well after bedtime, among other excuses...\n",
      "--------------------------------------------------\n",
      "Entire Text:\n",
      "Arming and supplying a generation of hostile youth whose land you invaded, in an area of land your being pushed out of, by the countryman of those you plan to arm... what could possibly go wrong?! Operation: Let's lose faster?\n",
      "Technically, yes. But unfortunately, â€œtechnicallyâ€ doesnâ€™t mean a lot in international diplomacy. I wrote another brief comment here about why â€œyes, it isâ€, but also why â€œyes, but who cares.â€.\n",
      "Hostile territory, essentially. Mines, shelling, drones, just angry Ukrainians with guns (assuming these kids have no white flag above their heads, but even then, its not always going to save them, especially since russhists used white flag for deception). Lack of food and heating will not help them either. And if they are unlucky, they will have squads nearby formed specifically to prevent them from escaping. Either they'll be captured or killed.\n",
      "Bahaha. Clearly, you've never tried putting a 5-year-old to bed. You may think \"case closed, \" but you've forgotten the water break, the pee break, the \"I don't like this color of night light\" get up, the whole recollection of their day to only be recited well after bedtime, among other excuses...\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd5db55e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Posts: 4200\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e87fa84a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Post Number                                JSON Data  \\\n",
      "0            1        {'authors': 2, 'changes': [1, 0]}   \n",
      "1            2  {'authors': 3, 'changes': [1, 1, 0, 1]}   \n",
      "2            3     {'authors': 3, 'changes': [1, 1, 1]}   \n",
      "3            4           {'authors': 2, 'changes': [1]}   \n",
      "4            5     {'authors': 4, 'changes': [1, 1, 1]}   \n",
      "\n",
      "                                           Text Data  \n",
      "0  I'm not arguing with you here, I'm simply tryi...  \n",
      "1  Biden has the power to write an executive orde...  \n",
      "2  In general, be courteous to others. Debate/dis...  \n",
      "3  Second, until late in the 20th century, the Ot...  \n",
      "4  Arming and supplying a generation of hostile y...  \n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c696f6ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Post Number</th>\n",
       "      <th>JSON Data</th>\n",
       "      <th>Text Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>{'authors': 2, 'changes': [1, 0]}</td>\n",
       "      <td>I'm not arguing with you here, I'm simply tryi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>{'authors': 3, 'changes': [1, 1, 0, 1]}</td>\n",
       "      <td>Biden has the power to write an executive orde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>{'authors': 3, 'changes': [1, 1, 1]}</td>\n",
       "      <td>In general, be courteous to others. Debate/dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>{'authors': 2, 'changes': [1]}</td>\n",
       "      <td>Second, until late in the 20th century, the Ot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>{'authors': 4, 'changes': [1, 1, 1]}</td>\n",
       "      <td>Arming and supplying a generation of hostile y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4195</th>\n",
       "      <td>4196</td>\n",
       "      <td>{'authors': 2, 'changes': [1, 1]}</td>\n",
       "      <td>Yeah fair enough, I kind of figured I was prob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4196</th>\n",
       "      <td>4197</td>\n",
       "      <td>{'authors': 2, 'changes': [1]}</td>\n",
       "      <td>No need for more suffering. Being a russian is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4197</th>\n",
       "      <td>4198</td>\n",
       "      <td>{'authors': 4, 'changes': [1, 1, 1]}</td>\n",
       "      <td>- - - - - - - - - - - - - - - - - - - - - - - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4198</th>\n",
       "      <td>4199</td>\n",
       "      <td>{'authors': 3, 'changes': [1, 1]}</td>\n",
       "      <td>Kanye is being manipulated and taken advantage...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4199</th>\n",
       "      <td>4200</td>\n",
       "      <td>{'authors': 3, 'changes': [1, 1]}</td>\n",
       "      <td>It appears you forgot to include your location...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4200 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Post Number                                JSON Data  \\\n",
       "0               1        {'authors': 2, 'changes': [1, 0]}   \n",
       "1               2  {'authors': 3, 'changes': [1, 1, 0, 1]}   \n",
       "2               3     {'authors': 3, 'changes': [1, 1, 1]}   \n",
       "3               4           {'authors': 2, 'changes': [1]}   \n",
       "4               5     {'authors': 4, 'changes': [1, 1, 1]}   \n",
       "...           ...                                      ...   \n",
       "4195         4196        {'authors': 2, 'changes': [1, 1]}   \n",
       "4196         4197           {'authors': 2, 'changes': [1]}   \n",
       "4197         4198     {'authors': 4, 'changes': [1, 1, 1]}   \n",
       "4198         4199        {'authors': 3, 'changes': [1, 1]}   \n",
       "4199         4200        {'authors': 3, 'changes': [1, 1]}   \n",
       "\n",
       "                                              Text Data  \n",
       "0     I'm not arguing with you here, I'm simply tryi...  \n",
       "1     Biden has the power to write an executive orde...  \n",
       "2     In general, be courteous to others. Debate/dis...  \n",
       "3     Second, until late in the 20th century, the Ot...  \n",
       "4     Arming and supplying a generation of hostile y...  \n",
       "...                                                 ...  \n",
       "4195  Yeah fair enough, I kind of figured I was prob...  \n",
       "4196  No need for more suffering. Being a russian is...  \n",
       "4197  - - - - - - - - - - - - - - - - - - - - - - - ...  \n",
       "4198  Kanye is being manipulated and taken advantage...  \n",
       "4199  It appears you forgot to include your location...  \n",
       "\n",
       "[4200 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43903689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Posts: 4200\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "daa54bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Post Number                                JSON Data  Authors  \\\n",
      "0            1        {'authors': 2, 'changes': [1, 0]}        2   \n",
      "1            2  {'authors': 3, 'changes': [1, 1, 0, 1]}        3   \n",
      "2            3     {'authors': 3, 'changes': [1, 1, 1]}        3   \n",
      "3            4           {'authors': 2, 'changes': [1]}        2   \n",
      "4            5     {'authors': 4, 'changes': [1, 1, 1]}        4   \n",
      "\n",
      "        Changes                                          Text Data  \n",
      "0        [1, 0]  I'm not arguing with you here, I'm simply tryi...  \n",
      "1  [1, 1, 0, 1]  Biden has the power to write an executive orde...  \n",
      "2     [1, 1, 1]  In general, be courteous to others. Debate/dis...  \n",
      "3           [1]  Second, until late in the 20th century, the Ot...  \n",
      "4     [1, 1, 1]  Arming and supplying a generation of hostile y...  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10582a68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Post Number</th>\n",
       "      <th>JSON Data</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Changes</th>\n",
       "      <th>Text Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>{'authors': 2, 'changes': [1, 0]}</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>I'm not arguing with you here, I'm simply tryi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>{'authors': 3, 'changes': [1, 1, 0, 1]}</td>\n",
       "      <td>3</td>\n",
       "      <td>[1, 1, 0, 1]</td>\n",
       "      <td>Biden has the power to write an executive orde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>{'authors': 3, 'changes': [1, 1, 1]}</td>\n",
       "      <td>3</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "      <td>In general, be courteous to others. Debate/dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>{'authors': 2, 'changes': [1]}</td>\n",
       "      <td>2</td>\n",
       "      <td>[1]</td>\n",
       "      <td>Second, until late in the 20th century, the Ot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>{'authors': 4, 'changes': [1, 1, 1]}</td>\n",
       "      <td>4</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "      <td>Arming and supplying a generation of hostile y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4195</th>\n",
       "      <td>4196</td>\n",
       "      <td>{'authors': 2, 'changes': [1, 1]}</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>Yeah fair enough, I kind of figured I was prob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4196</th>\n",
       "      <td>4197</td>\n",
       "      <td>{'authors': 2, 'changes': [1]}</td>\n",
       "      <td>2</td>\n",
       "      <td>[1]</td>\n",
       "      <td>No need for more suffering. Being a russian is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4197</th>\n",
       "      <td>4198</td>\n",
       "      <td>{'authors': 4, 'changes': [1, 1, 1]}</td>\n",
       "      <td>4</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "      <td>- - - - - - - - - - - - - - - - - - - - - - - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4198</th>\n",
       "      <td>4199</td>\n",
       "      <td>{'authors': 3, 'changes': [1, 1]}</td>\n",
       "      <td>3</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>Kanye is being manipulated and taken advantage...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4199</th>\n",
       "      <td>4200</td>\n",
       "      <td>{'authors': 3, 'changes': [1, 1]}</td>\n",
       "      <td>3</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>It appears you forgot to include your location...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4200 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Post Number                                JSON Data  Authors  \\\n",
       "0               1        {'authors': 2, 'changes': [1, 0]}        2   \n",
       "1               2  {'authors': 3, 'changes': [1, 1, 0, 1]}        3   \n",
       "2               3     {'authors': 3, 'changes': [1, 1, 1]}        3   \n",
       "3               4           {'authors': 2, 'changes': [1]}        2   \n",
       "4               5     {'authors': 4, 'changes': [1, 1, 1]}        4   \n",
       "...           ...                                      ...      ...   \n",
       "4195         4196        {'authors': 2, 'changes': [1, 1]}        2   \n",
       "4196         4197           {'authors': 2, 'changes': [1]}        2   \n",
       "4197         4198     {'authors': 4, 'changes': [1, 1, 1]}        4   \n",
       "4198         4199        {'authors': 3, 'changes': [1, 1]}        3   \n",
       "4199         4200        {'authors': 3, 'changes': [1, 1]}        3   \n",
       "\n",
       "           Changes                                          Text Data  \n",
       "0           [1, 0]  I'm not arguing with you here, I'm simply tryi...  \n",
       "1     [1, 1, 0, 1]  Biden has the power to write an executive orde...  \n",
       "2        [1, 1, 1]  In general, be courteous to others. Debate/dis...  \n",
       "3              [1]  Second, until late in the 20th century, the Ot...  \n",
       "4        [1, 1, 1]  Arming and supplying a generation of hostile y...  \n",
       "...            ...                                                ...  \n",
       "4195        [1, 1]  Yeah fair enough, I kind of figured I was prob...  \n",
       "4196           [1]  No need for more suffering. Being a russian is...  \n",
       "4197     [1, 1, 1]  - - - - - - - - - - - - - - - - - - - - - - - ...  \n",
       "4198        [1, 1]  Kanye is being manipulated and taken advantage...  \n",
       "4199        [1, 1]  It appears you forgot to include your location...  \n",
       "\n",
       "[4200 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00ecaab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 4], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61a5dc1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Author Count  Count\n",
      "0             2   1400\n",
      "1             3   1400\n",
      "2             4   1400\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f51a322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4200 entries, 0 to 4199\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Post Number  4200 non-null   int64 \n",
      " 1   JSON Data    4200 non-null   object\n",
      " 2   Authors      4200 non-null   int64 \n",
      " 3   Changes      4200 non-null   object\n",
      " 4   Text Data    4200 non-null   object\n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 164.2+ KB\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "459deddc",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'C:\\\\Users\\\\EBRAHIMR2\\\\Downloads\\\\Data Science Masters\\\\Modules\\\\COS 801\\\\pan23-multi-author-analysis-dataset1\\\\pan23-multi-author-analysis-dataset1-train\\\\output.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m excel_file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_folder, excel_file_name)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Write the DataFrame to an Excel file\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexcel_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Set index=False to exclude index column\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexcel_file_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:2374\u001b[0m, in \u001b[0;36mNDFrame.to_excel\u001b[1;34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, encoding, inf_rep, verbose, freeze_panes, storage_options)\u001b[0m\n\u001b[0;32m   2361\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mformats\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexcel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExcelFormatter\n\u001b[0;32m   2363\u001b[0m formatter \u001b[38;5;241m=\u001b[39m ExcelFormatter(\n\u001b[0;32m   2364\u001b[0m     df,\n\u001b[0;32m   2365\u001b[0m     na_rep\u001b[38;5;241m=\u001b[39mna_rep,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2372\u001b[0m     inf_rep\u001b[38;5;241m=\u001b[39minf_rep,\n\u001b[0;32m   2373\u001b[0m )\n\u001b[1;32m-> 2374\u001b[0m \u001b[43mformatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2375\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexcel_writer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2376\u001b[0m \u001b[43m    \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2377\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstartrow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstartrow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstartcol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstartcol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2379\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfreeze_panes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreeze_panes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2382\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\excel.py:944\u001b[0m, in \u001b[0;36mExcelFormatter.write\u001b[1;34m(self, writer, sheet_name, startrow, startcol, freeze_panes, engine, storage_options)\u001b[0m\n\u001b[0;32m    940\u001b[0m     need_save \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    941\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    942\u001b[0m     \u001b[38;5;66;03m# error: Cannot instantiate abstract class 'ExcelWriter' with abstract\u001b[39;00m\n\u001b[0;32m    943\u001b[0m     \u001b[38;5;66;03m# attributes 'engine', 'save', 'supported_extensions' and 'write_cells'\u001b[39;00m\n\u001b[1;32m--> 944\u001b[0m     writer \u001b[38;5;241m=\u001b[39m \u001b[43mExcelWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[abstract]\u001b[39;49;00m\n\u001b[0;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[0;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    947\u001b[0m     need_save \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    949\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:60\u001b[0m, in \u001b[0;36mOpenpyxlWriter.__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenpyxl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mworkbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Workbook\n\u001b[0;32m     58\u001b[0m engine_kwargs \u001b[38;5;241m=\u001b[39m combine_kwargs(engine_kwargs, kwargs)\n\u001b[1;32m---> 60\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43mif_sheet_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_sheet_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# ExcelWriter replaced \"a\" by \"r+\" to allow us to first read the excel file from\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# the file and later write to it\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode:  \u001b[38;5;66;03m# Load from existing workbook\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1313\u001b[0m, in \u001b[0;36mExcelWriter.__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m   1309\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handles \u001b[38;5;241m=\u001b[39m IOHandles(\n\u001b[0;32m   1310\u001b[0m     cast(IO[\u001b[38;5;28mbytes\u001b[39m], path), compression\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[0;32m   1311\u001b[0m )\n\u001b[0;32m   1312\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, ExcelWriter):\n\u001b[1;32m-> 1313\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m   1315\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1316\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cur_sheet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m date_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py:865\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    857\u001b[0m             handle,\n\u001b[0;32m    858\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    861\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    862\u001b[0m         )\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    866\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    868\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'C:\\\\Users\\\\EBRAHIMR2\\\\Downloads\\\\Data Science Masters\\\\Modules\\\\COS 801\\\\pan23-multi-author-analysis-dataset1\\\\pan23-multi-author-analysis-dataset1-train\\\\output.xlsx'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16424281",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c44cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68861f67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6766edc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9401a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7069a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2932ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93024636",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf6f227",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
